{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 13:14:05,924 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "2025-06-05 13:14:06,587 - httpx - INFO - HTTP Request: GET http://localhost:9999/api/v2/auth/identity \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:14:06,605 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "2025-06-05 13:14:07,203 - httpx - INFO - HTTP Request: GET http://localhost:9999/api/v2/tenants/default_tenant \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:14:07,229 - httpx - INFO - HTTP Request: GET http://localhost:9999/api/v2/tenants/default_tenant/databases/default_database \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:14:08,224 - httpx - INFO - HTTP Request: POST http://localhost:9999/api/v2/tenants/default_tenant/databases/default_database/collections \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema.document import Document\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "import chromadb\n",
    "from server.v1.config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniversityDataProcessor:\n",
    "    def __init__(self, data_root=\"data/courses\"):\n",
    "        self.data_root = Path(data_root)\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000, \n",
    "            chunk_overlap=200\n",
    "        )\n",
    "        self.embedding_model = OllamaEmbeddings(model=config.retrieval.embedding_model)\n",
    "        \n",
    "    def extract_metadata_from_path(self, file_path: Path):\n",
    "        \"\"\"Extract metadata from file path structure\"\"\"\n",
    "        parts = file_path.parts\n",
    "        \n",
    "        # Find course, content_type, and specific info\n",
    "        course_idx = None\n",
    "        for i, part in enumerate(parts):\n",
    "            if part == \"courses\" and i + 1 < len(parts):\n",
    "                course_idx = i + 1\n",
    "                break\n",
    "                \n",
    "        if course_idx is None:\n",
    "            return {}\n",
    "            \n",
    "        course = parts[course_idx] if course_idx < len(parts) else \"unknown\"\n",
    "        content_type = parts[course_idx + 1] if course_idx + 1 < len(parts) else \"unknown\"\n",
    "        \n",
    "        metadata = {\n",
    "            \"course\": course,\n",
    "            \"content_type\": content_type,  # \"books\" or \"lectures\"\n",
    "            \"file_name\": file_path.stem,\n",
    "            \"file_type\": file_path.suffix.lower(),\n",
    "            \"source_path\": str(file_path)\n",
    "        }\n",
    "        \n",
    "        if content_type == \"lectures\" and course_idx + 2 < len(parts):\n",
    "            metadata[\"teacher\"] = parts[course_idx + 2]\n",
    "            \n",
    "        return metadata\n",
    "    \n",
    "    def load_teacher_metadata(self, teacher_dir: Path):\n",
    "        \"\"\"Load teacher-specific metadata if available\"\"\"\n",
    "        metadata_file = teacher_dir / \"metadata.json\"\n",
    "        if metadata_file.exists():\n",
    "            with open(metadata_file, 'r', encoding='utf-8') as f:\n",
    "                return json.load(f)\n",
    "        return {}\n",
    "    \n",
    "    def process_book(self, file_path: Path):\n",
    "        \"\"\"Process a book PDF with enhanced metadata\"\"\"\n",
    "        base_metadata = self.extract_metadata_from_path(file_path)\n",
    "        \n",
    "        # Add book-specific metadata\n",
    "        base_metadata.update({\n",
    "            \"document_type\": \"textbook\",\n",
    "            \"subject_area\": self.infer_subject_from_filename(file_path.stem)\n",
    "        })\n",
    "        \n",
    "        loader = PyPDFLoader(str(file_path))\n",
    "        pages = loader.load()\n",
    "        \n",
    "        documents = []\n",
    "        for page in pages:\n",
    "            # Split long pages into chunks\n",
    "            chunks = self.text_splitter.split_text(page.page_content)\n",
    "            \n",
    "            for i, chunk in enumerate(chunks):\n",
    "                if len(chunk.strip()) < 50:  # Skip very short chunks\n",
    "                    continue\n",
    "                    \n",
    "                doc_metadata = {\n",
    "                    **base_metadata,\n",
    "                    \"page_number\": page.metadata.get(\"page\", 0),\n",
    "                    \"chunk_index\": i,\n",
    "                    \"total_pages\": len(pages)\n",
    "                }\n",
    "                \n",
    "                # Extract chapter info if possible\n",
    "                chapter_info = self.extract_chapter_info(chunk)\n",
    "                if chapter_info:\n",
    "                    doc_metadata.update(chapter_info)\n",
    "                \n",
    "                documents.append(Document(\n",
    "                    page_content=chunk,\n",
    "                    metadata=doc_metadata\n",
    "                ))\n",
    "        \n",
    "        return documents\n",
    "    \n",
    "    def process_lecture(self, file_path: Path):\n",
    "        \"\"\"Process a lecture PDF with teacher and course metadata\"\"\"\n",
    "        base_metadata = self.extract_metadata_from_path(file_path)\n",
    "        \n",
    "        # Load teacher metadata\n",
    "        teacher_dir = file_path.parent\n",
    "        teacher_metadata = self.load_teacher_metadata(teacher_dir)\n",
    "        \n",
    "        base_metadata.update({\n",
    "            \"document_type\": \"lecture\",\n",
    "            \"teacher_info\": teacher_metadata.get(\"teacher_name\", base_metadata.get(\"teacher\", \"unknown\")),\n",
    "            \"course_code\": teacher_metadata.get(\"course_code\", \"\"),\n",
    "            \"semester\": teacher_metadata.get(\"semester\", \"\"),\n",
    "            \"academic_year\": teacher_metadata.get(\"academic_year\", \"\")\n",
    "        })\n",
    "        \n",
    "        # Extract lecture-specific info from filename\n",
    "        lecture_info = self.extract_lecture_info(file_path.stem)\n",
    "        base_metadata.update(lecture_info)\n",
    "        \n",
    "        loader = PyPDFLoader(str(file_path))\n",
    "        pages = loader.load()\n",
    "        \n",
    "        documents = []\n",
    "        for page in pages:\n",
    "            chunks = self.text_splitter.split_text(page.page_content)\n",
    "            \n",
    "            for i, chunk in enumerate(chunks):\n",
    "                if len(chunk.strip()) < 50:\n",
    "                    continue\n",
    "                    \n",
    "                doc_metadata = {\n",
    "                    **base_metadata,\n",
    "                    \"page_number\": page.metadata.get(\"page\", 0),\n",
    "                    \"chunk_index\": i,\n",
    "                    \"total_pages\": len(pages)\n",
    "                }\n",
    "                \n",
    "                documents.append(Document(\n",
    "                    page_content=chunk,\n",
    "                    metadata=doc_metadata\n",
    "                ))\n",
    "        \n",
    "        return documents\n",
    "    \n",
    "    def extract_chapter_info(self, text: str):\n",
    "        \"\"\"Extract chapter information from text content\"\"\"\n",
    "        import re\n",
    "        \n",
    "        # Look for chapter patterns\n",
    "        chapter_patterns = [\n",
    "            r\"Chapter\\s+(\\d+)[:\\s]*(.+?)(?:\\n|$)\",\n",
    "            r\"CHAPTER\\s+(\\d+)[:\\s]*(.+?)(?:\\n|$)\",\n",
    "            r\"Ch\\.\\s*(\\d+)[:\\s]*(.+?)(?:\\n|$)\"\n",
    "        ]\n",
    "        \n",
    "        for pattern in chapter_patterns:\n",
    "            match = re.search(pattern, text, re.IGNORECASE | re.MULTILINE)\n",
    "            if match:\n",
    "                return {\n",
    "                    \"chapter_number\": int(match.group(1)),\n",
    "                    \"chapter_title\": match.group(2).strip()\n",
    "                }\n",
    "        \n",
    "        return {}\n",
    "    \n",
    "    def extract_lecture_info(self, filename: str):\n",
    "        \"\"\"Extract lecture-specific info from filename\"\"\"\n",
    "        import re\n",
    "        \n",
    "        info = {}\n",
    "        \n",
    "        # Extract week number\n",
    "        week_match = re.search(r\"week(\\d+)\", filename, re.IGNORECASE)\n",
    "        if week_match:\n",
    "            info[\"week_number\"] = int(week_match.group(1))\n",
    "        \n",
    "        # Extract lecture number\n",
    "        lecture_match = re.search(r\"lecture(\\d+)\", filename, re.IGNORECASE)\n",
    "        if lecture_match:\n",
    "            info[\"lecture_number\"] = int(lecture_match.group(1))\n",
    "        \n",
    "        # Extract topic from filename (everything after week/lecture info)\n",
    "        topic_match = re.search(r\"(?:week\\d+_|lecture\\d+_)(.+)\", filename, re.IGNORECASE)\n",
    "        if topic_match:\n",
    "            info[\"topic\"] = topic_match.group(1).replace(\"_\", \" \").title()\n",
    "        \n",
    "        return info\n",
    "    \n",
    "    def infer_subject_from_filename(self, filename: str):\n",
    "        \"\"\"Infer subject area from filename\"\"\"\n",
    "        filename_lower = filename.lower()\n",
    "        \n",
    "        subject_keywords = {\n",
    "            \"mechanics\": [\"static\", \"dynamic\", \"mechanic\", \"force\", \"motion\"],\n",
    "            \"thermodynamics\": [\"thermo\", \"heat\", \"energy\", \"entropy\"],\n",
    "            \"materials\": [\"material\", \"steel\", \"concrete\", \"composite\"],\n",
    "            \"fluid_mechanics\": [\"fluid\", \"flow\", \"hydraulic\", \"pneumatic\"],\n",
    "            \"mathematics\": [\"calculus\", \"algebra\", \"differential\", \"linear\"],\n",
    "            \"electronics\": [\"circuit\", \"electronic\", \"digital\", \"analog\"]\n",
    "        }\n",
    "        \n",
    "        for subject, keywords in subject_keywords.items():\n",
    "            if any(keyword in filename_lower for keyword in keywords):\n",
    "                return subject\n",
    "        \n",
    "        return \"general\"\n",
    "    \n",
    "    def process_all_files(self):\n",
    "        \"\"\"Process all PDF files in the data structure\"\"\"\n",
    "        all_documents = []\n",
    "        \n",
    "        for course_dir in self.data_root.iterdir():\n",
    "            if not course_dir.is_dir():\n",
    "                continue\n",
    "                \n",
    "            print(f\"Processing course: {course_dir.name}\")\n",
    "            \n",
    "            # Process books\n",
    "            books_dir = course_dir / \"books\"\n",
    "            if books_dir.exists():\n",
    "                for book_file in books_dir.glob(\"*.pdf\"):\n",
    "                    print(f\"  Processing book: {book_file.name}\")\n",
    "                    documents = self.process_book(book_file)\n",
    "                    all_documents.extend(documents)\n",
    "            \n",
    "            # Process lectures\n",
    "            lectures_dir = course_dir / \"lectures\"\n",
    "            if lectures_dir.exists():\n",
    "                for teacher_dir in lectures_dir.iterdir():\n",
    "                    if not teacher_dir.is_dir():\n",
    "                        continue\n",
    "                    \n",
    "                    print(f\"  Processing teacher: {teacher_dir.name}\")\n",
    "                    for lecture_file in teacher_dir.glob(\"*.pdf\"):\n",
    "                        print(f\"    Processing lecture: {lecture_file.name}\")\n",
    "                        documents = self.process_lecture(lecture_file)\n",
    "                        all_documents.extend(documents)\n",
    "        \n",
    "        return all_documents\n",
    "    \n",
    "    def create_vector_database(self, documents, batch_size=250, collection_name=\"university_study\"):\n",
    "        \"\"\"Create ChromaDB with processed documents\"\"\"\n",
    "        persistent_client = chromadb.HttpClient(port=config.retrieval.chroma_port)\n",
    "        vector_db = Chroma(\n",
    "            embedding_function=self.embedding_model,\n",
    "            client=persistent_client,\n",
    "            collection_name=collection_name,\n",
    "            collection_metadata={'id': collection_name},\n",
    "            create_collection_if_not_exists=True,\n",
    "        )\n",
    "\n",
    "        for i in range(0, len(documents), batch_size):\n",
    "            vector_db.add_documents(documents[i:i+batch_size])\n",
    "        \n",
    "        return vector_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing course: Fluid Machinery\n",
      "  Processing teacher: mamun\n",
      "    Processing lecture: S1_Introduction.pdf\n",
      "    Processing lecture: S2_Reciprocating_Pump.pdf\n",
      "    Processing lecture: S3_Centrifugal_Pumps.pdf\n",
      "Processing course: Internal Combustion Engines\n",
      "  Processing book: Ferguson 3rd ed.pdf\n",
      "  Processing book: Heywood 2nd ed.pdf\n",
      "  Processing teacher: anup\n",
      "    Processing lecture: Lec1_Engine Basics.pdf\n",
      "    Processing lecture: Lec2_Engine Basics.pdf\n",
      "    Processing lecture: Lec3_Engine Performance Parameters.pdf\n",
      "    Processing lecture: Lec4_IC Engine Cycles.pdf\n",
      "    Processing lecture: Lec5_IC Engine Cycles.pdf\n",
      "    Processing lecture: Lec6_IC Engine-Air standard Cycle.pdf\n",
      "  Processing teacher: monjur\n",
      "    Processing lecture: 1.IC-Engine-History.pdf\n",
      "    Processing lecture: 2.IC-Engine-Fuel.pdf\n",
      "    Processing lecture: 3.IC-Engine-Combustion-SI.pdf\n",
      "    Processing lecture: 4.IC-Engine-Combustion-CI.pdf\n",
      "Processing course: Noise and Vibration\n",
      "  Processing book: Rao 6th ed.pdf\n",
      "  Processing teacher: ashiq\n",
      "    Processing lecture: Damping to Forced Vibration.pdf\n",
      "    Processing lecture: ME445 2DOFS.pdf\n",
      "    Processing lecture: ME445 Lectures 1,2,3...pdf\n",
      "Processing course: Refrigeration and Building Mechanical System\n",
      "  Processing teacher: aloke\n",
      "    Processing lecture: 1.Different Refrigeration Systems.pdf\n",
      "    Processing lecture: 2. Compressors.pdf\n",
      "    Processing lecture: 3. Condenser.pdf\n",
      "  Processing teacher: ashiqur\n",
      "    Processing lecture: Lecture 1_ME 415_Fire Hazard_12 April 2025.pdf\n",
      "    Processing lecture: Lecture 2_ME 415_Basics on Fire Dynamics_19 April 2025.pdf\n",
      "    Processing lecture: Lecture 3_ME 415_Extinguishment of Fire_26 April 2025.pdf\n",
      "    Processing lecture: Lecture 4 _ME 415_Fire Detection and Alarm System_03 May 2025.pdf\n",
      "    Processing lecture: Lecture 5 _ME 415_Fire Detection and Alarm System_17 May 2025.pdf\n",
      "    Processing lecture: Lecture 6_ME 415_Fire Protection System_24 May 2025.pdf\n",
      "  Processing teacher: mamun\n",
      "    Processing lecture: Lecture 1.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 13:18:37,714 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 8452 document chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 13:18:38,389 - httpx - INFO - HTTP Request: GET http://localhost:9999/api/v2/auth/identity \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:18:38,391 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "2025-06-05 13:18:38,868 - httpx - INFO - HTTP Request: GET http://localhost:9999/api/v2/tenants/default_tenant \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:18:38,879 - httpx - INFO - HTTP Request: GET http://localhost:9999/api/v2/tenants/default_tenant/databases/default_database \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:18:39,055 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=1, read=2, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001EA284A17D0>: Failed to resolve 'us.i.posthog.com' ([Errno 11001] getaddrinfo failed)\")': /batch/\n",
      "2025-06-05 13:18:39,060 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=0, read=2, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001EA49D15E50>: Failed to resolve 'us.i.posthog.com' ([Errno 11001] getaddrinfo failed)\")': /batch/\n",
      "2025-06-05 13:18:39,074 - httpx - INFO - HTTP Request: POST http://localhost:9999/api/v2/tenants/default_tenant/databases/default_database/collections \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:18:39,087 - backoff - INFO - Backing off send_request(...) for 0.9s (requests.exceptions.ConnectionError: HTTPSConnectionPool(host='us.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001EA4832C550>: Failed to resolve 'us.i.posthog.com' ([Errno 11001] getaddrinfo failed)\")))\n",
      "2025-06-05 13:18:40,023 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=1, read=2, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001EAAC15BB50>: Failed to resolve 'us.i.posthog.com' ([Errno 11001] getaddrinfo failed)\")': /batch/\n",
      "2025-06-05 13:18:40,026 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=0, read=2, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001EA4832D390>: Failed to resolve 'us.i.posthog.com' ([Errno 11001] getaddrinfo failed)\")': /batch/\n",
      "2025-06-05 13:18:40,030 - backoff - INFO - Backing off send_request(...) for 0.6s (requests.exceptions.ConnectionError: HTTPSConnectionPool(host='us.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001EA49D164D0>: Failed to resolve 'us.i.posthog.com' ([Errno 11001] getaddrinfo failed)\")))\n",
      "2025-06-05 13:18:40,607 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=1, read=2, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001EA49D17210>: Failed to resolve 'us.i.posthog.com' ([Errno 11001] getaddrinfo failed)\")': /batch/\n",
      "2025-06-05 13:18:40,609 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=0, read=2, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001EA49977550>: Failed to resolve 'us.i.posthog.com' ([Errno 11001] getaddrinfo failed)\")': /batch/\n",
      "2025-06-05 13:18:40,614 - backoff - INFO - Backing off send_request(...) for 0.4s (requests.exceptions.ConnectionError: HTTPSConnectionPool(host='us.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001EA4377D410>: Failed to resolve 'us.i.posthog.com' ([Errno 11001] getaddrinfo failed)\")))\n",
      "2025-06-05 13:18:41,032 - urllib3.connectionpool - WARNING - Retrying (Retry(total=1, connect=1, read=2, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001EAAC158190>: Failed to resolve 'us.i.posthog.com' ([Errno 11001] getaddrinfo failed)\")': /batch/\n",
      "2025-06-05 13:18:41,036 - urllib3.connectionpool - WARNING - Retrying (Retry(total=0, connect=0, read=2, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001EAAC158A10>: Failed to resolve 'us.i.posthog.com' ([Errno 11001] getaddrinfo failed)\")': /batch/\n",
      "2025-06-05 13:18:41,041 - backoff - ERROR - Giving up send_request(...) after 4 tries (requests.exceptions.ConnectionError: HTTPSConnectionPool(host='us.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001EA48331F10>: Failed to resolve 'us.i.posthog.com' ([Errno 11001] getaddrinfo failed)\")))\n",
      "2025-06-05 13:18:51,781 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:18:51,988 - httpx - INFO - HTTP Request: GET http://localhost:9999/api/v2/pre-flight-checks \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:19:00,063 - httpx - INFO - HTTP Request: POST http://localhost:9999/api/v2/tenants/default_tenant/databases/default_database/collections/4b254101-5eb3-4574-93bf-13c7c83010d8/upsert \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:19:08,836 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:19:14,884 - httpx - INFO - HTTP Request: POST http://localhost:9999/api/v2/tenants/default_tenant/databases/default_database/collections/4b254101-5eb3-4574-93bf-13c7c83010d8/upsert \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:19:23,133 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:19:28,526 - httpx - INFO - HTTP Request: POST http://localhost:9999/api/v2/tenants/default_tenant/databases/default_database/collections/4b254101-5eb3-4574-93bf-13c7c83010d8/upsert \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:19:37,394 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:19:45,196 - httpx - INFO - HTTP Request: POST http://localhost:9999/api/v2/tenants/default_tenant/databases/default_database/collections/4b254101-5eb3-4574-93bf-13c7c83010d8/upsert \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:19:53,466 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:20:02,271 - httpx - INFO - HTTP Request: POST http://localhost:9999/api/v2/tenants/default_tenant/databases/default_database/collections/4b254101-5eb3-4574-93bf-13c7c83010d8/upsert \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:20:11,847 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:20:18,557 - httpx - INFO - HTTP Request: POST http://localhost:9999/api/v2/tenants/default_tenant/databases/default_database/collections/4b254101-5eb3-4574-93bf-13c7c83010d8/upsert \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:20:26,814 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:20:33,501 - httpx - INFO - HTTP Request: POST http://localhost:9999/api/v2/tenants/default_tenant/databases/default_database/collections/4b254101-5eb3-4574-93bf-13c7c83010d8/upsert \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:20:41,604 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:20:50,559 - httpx - INFO - HTTP Request: POST http://localhost:9999/api/v2/tenants/default_tenant/databases/default_database/collections/4b254101-5eb3-4574-93bf-13c7c83010d8/upsert \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:20:59,854 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:21:07,444 - httpx - INFO - HTTP Request: POST http://localhost:9999/api/v2/tenants/default_tenant/databases/default_database/collections/4b254101-5eb3-4574-93bf-13c7c83010d8/upsert \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:21:16,232 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:21:21,946 - httpx - INFO - HTTP Request: POST http://localhost:9999/api/v2/tenants/default_tenant/databases/default_database/collections/4b254101-5eb3-4574-93bf-13c7c83010d8/upsert \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:21:30,396 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:21:36,481 - httpx - INFO - HTTP Request: POST http://localhost:9999/api/v2/tenants/default_tenant/databases/default_database/collections/4b254101-5eb3-4574-93bf-13c7c83010d8/upsert \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:21:44,932 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:21:53,976 - httpx - INFO - HTTP Request: POST http://localhost:9999/api/v2/tenants/default_tenant/databases/default_database/collections/4b254101-5eb3-4574-93bf-13c7c83010d8/upsert \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:22:02,804 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:22:08,710 - httpx - INFO - HTTP Request: POST http://localhost:9999/api/v2/tenants/default_tenant/databases/default_database/collections/4b254101-5eb3-4574-93bf-13c7c83010d8/upsert \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:22:16,907 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:22:32,292 - httpx - INFO - HTTP Request: POST http://localhost:9999/api/v2/tenants/default_tenant/databases/default_database/collections/4b254101-5eb3-4574-93bf-13c7c83010d8/upsert \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:22:40,918 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:22:51,286 - httpx - INFO - HTTP Request: POST http://localhost:9999/api/v2/tenants/default_tenant/databases/default_database/collections/4b254101-5eb3-4574-93bf-13c7c83010d8/upsert \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:22:59,545 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:23:10,931 - httpx - INFO - HTTP Request: POST http://localhost:9999/api/v2/tenants/default_tenant/databases/default_database/collections/4b254101-5eb3-4574-93bf-13c7c83010d8/upsert \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:23:19,470 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:23:24,855 - httpx - INFO - HTTP Request: POST http://localhost:9999/api/v2/tenants/default_tenant/databases/default_database/collections/4b254101-5eb3-4574-93bf-13c7c83010d8/upsert \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:23:33,000 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:23:42,405 - httpx - INFO - HTTP Request: POST http://localhost:9999/api/v2/tenants/default_tenant/databases/default_database/collections/4b254101-5eb3-4574-93bf-13c7c83010d8/upsert \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:23:50,798 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:23:56,699 - httpx - INFO - HTTP Request: POST http://localhost:9999/api/v2/tenants/default_tenant/databases/default_database/collections/4b254101-5eb3-4574-93bf-13c7c83010d8/upsert \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:24:05,504 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:24:17,853 - httpx - INFO - HTTP Request: POST http://localhost:9999/api/v2/tenants/default_tenant/databases/default_database/collections/4b254101-5eb3-4574-93bf-13c7c83010d8/upsert \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:24:25,352 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:24:28,517 - httpx - INFO - HTTP Request: POST http://localhost:9999/api/v2/tenants/default_tenant/databases/default_database/collections/4b254101-5eb3-4574-93bf-13c7c83010d8/upsert \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:24:37,085 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:24:44,719 - httpx - INFO - HTTP Request: POST http://localhost:9999/api/v2/tenants/default_tenant/databases/default_database/collections/4b254101-5eb3-4574-93bf-13c7c83010d8/upsert \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:24:53,606 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:25:01,842 - httpx - INFO - HTTP Request: POST http://localhost:9999/api/v2/tenants/default_tenant/databases/default_database/collections/4b254101-5eb3-4574-93bf-13c7c83010d8/upsert \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:25:10,956 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:25:21,943 - httpx - INFO - HTTP Request: POST http://localhost:9999/api/v2/tenants/default_tenant/databases/default_database/collections/4b254101-5eb3-4574-93bf-13c7c83010d8/upsert \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:25:30,728 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:25:36,492 - httpx - INFO - HTTP Request: POST http://localhost:9999/api/v2/tenants/default_tenant/databases/default_database/collections/4b254101-5eb3-4574-93bf-13c7c83010d8/upsert \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:25:45,051 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:25:50,678 - httpx - INFO - HTTP Request: POST http://localhost:9999/api/v2/tenants/default_tenant/databases/default_database/collections/4b254101-5eb3-4574-93bf-13c7c83010d8/upsert \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:25:59,803 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:26:06,691 - httpx - INFO - HTTP Request: POST http://localhost:9999/api/v2/tenants/default_tenant/databases/default_database/collections/4b254101-5eb3-4574-93bf-13c7c83010d8/upsert \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:26:16,036 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:26:24,570 - httpx - INFO - HTTP Request: POST http://localhost:9999/api/v2/tenants/default_tenant/databases/default_database/collections/4b254101-5eb3-4574-93bf-13c7c83010d8/upsert \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:26:33,394 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:26:39,181 - httpx - INFO - HTTP Request: POST http://localhost:9999/api/v2/tenants/default_tenant/databases/default_database/collections/4b254101-5eb3-4574-93bf-13c7c83010d8/upsert \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:26:47,608 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:26:53,604 - httpx - INFO - HTTP Request: POST http://localhost:9999/api/v2/tenants/default_tenant/databases/default_database/collections/4b254101-5eb3-4574-93bf-13c7c83010d8/upsert \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:27:02,993 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:27:08,970 - httpx - INFO - HTTP Request: POST http://localhost:9999/api/v2/tenants/default_tenant/databases/default_database/collections/4b254101-5eb3-4574-93bf-13c7c83010d8/upsert \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:27:18,100 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:27:36,534 - httpx - INFO - HTTP Request: POST http://localhost:9999/api/v2/tenants/default_tenant/databases/default_database/collections/4b254101-5eb3-4574-93bf-13c7c83010d8/upsert \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:27:44,991 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:27:54,296 - httpx - INFO - HTTP Request: POST http://localhost:9999/api/v2/tenants/default_tenant/databases/default_database/collections/4b254101-5eb3-4574-93bf-13c7c83010d8/upsert \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:28:00,475 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:28:05,901 - httpx - INFO - HTTP Request: POST http://localhost:9999/api/v2/tenants/default_tenant/databases/default_database/collections/4b254101-5eb3-4574-93bf-13c7c83010d8/upsert \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 8452 document chunks\n"
     ]
    }
   ],
   "source": [
    "# Usage example\n",
    "processor = UniversityDataProcessor()\n",
    "all_documents = processor.process_all_files()\n",
    "print(f\"Processing {len(all_documents)} document chunks\")\n",
    "\n",
    "vector_db = processor.create_vector_database(all_documents)\n",
    "\n",
    "print(f\"Processed {len(all_documents)} document chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 13:28:49,958 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:28:54,547 - httpx - INFO - HTTP Request: POST http://localhost:9999/api/v2/tenants/default_tenant/databases/default_database/collections/4b254101-5eb3-4574-93bf-13c7c83010d8/query \"HTTP/1.1 200 OK\"\n",
      "2025-06-05 13:28:54,643 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(Document(id='5d37b919-3c67-4bcf-ba9a-dc891d28489c', metadata={'total_pages': 31, 'course': 'Refrigeration and Building Mechanical System', 'course_code': 'ME415', 'document_type': 'lecture', 'file_name': 'Lecture 2_ME 415_Basics on Fire Dynamics_19 April 2025', 'content_type': 'lectures', 'chunk_index': 0, 'file_type': '.pdf', 'academic_year': '4', 'source_path': 'data\\\\courses\\\\Refrigeration and Building Mechanical System\\\\lectures\\\\ashiqur\\\\Lecture 2_ME 415_Basics on Fire Dynamics_19 April 2025.pdf', 'semester': '1', 'page_number': 7, 'teacher': 'ashiqur', 'teacher_info': 'Dr. Md. Ashiqur Rahman'}, page_content='ME 415 Md. Ashiqur Rahman, ME, BUET\\noFire: \\no A fire is self-sustained oxidation of a fuel. \\no NFPA 921: \"A rapid oxidation process, which is a chemical reaction \\nresulting in the evolution of light and heat”.\\no Combustion or burning, in which substances combine chemically \\nwith oxygen from the air and typically give out bright light, heat, \\nand smoke.\\n\\uf09b Fire must have three things to \\nignite and maintain combustion:\\n− Fuel\\n− Heat \\n− Oxygen (air)\\nFire Triangle\\nFire Fundamentals'), 0.5819136), (Document(id='4cc26832-ac6b-4e85-975d-b1c2f83e3283', metadata={'file_name': 'Lecture 3_ME 415_Extinguishment of Fire_26 April 2025', 'teacher_info': 'Dr. Md. Ashiqur Rahman', 'document_type': 'lecture', 'teacher': 'ashiqur', 'semester': '1', 'file_type': '.pdf', 'content_type': 'lectures', 'course_code': 'ME415', 'total_pages': 31, 'course': 'Refrigeration and Building Mechanical System', 'chunk_index': 0, 'source_path': 'data\\\\courses\\\\Refrigeration and Building Mechanical System\\\\lectures\\\\ashiqur\\\\Lecture 3_ME 415_Extinguishment of Fire_26 April 2025.pdf', 'page_number': 2, 'academic_year': '4'}, page_content='ME 415 Md. Ashiqur Rahman\\no Once a fire begins, it requires four variables to sustain the \\ncombustion reaction. \\no The four variables required to sustain a fire are fuel, oxygen, heat, \\nand chemical chain reactions. These four variables represent the \\nfire tetrahedron. \\nFire Tetrahedron'), 0.5981427), (Document(id='ab39345b-01f3-43c6-884f-c887516d5ef5', metadata={'source_path': 'data\\\\courses\\\\Refrigeration and Building Mechanical System\\\\lectures\\\\ashiqur\\\\Lecture 3_ME 415_Extinguishment of Fire_26 April 2025.pdf', 'file_name': 'Lecture 3_ME 415_Extinguishment of Fire_26 April 2025', 'document_type': 'lecture', 'file_type': '.pdf', 'content_type': 'lectures', 'semester': '1', 'teacher_info': 'Dr. Md. Ashiqur Rahman', 'page_number': 25, 'course': 'Refrigeration and Building Mechanical System', 'teacher': 'ashiqur', 'total_pages': 31, 'chunk_index': 0, 'course_code': 'ME415', 'academic_year': '4'}, page_content='ME 415 Md. Ashiqur Rahman\\no Kitchen Fire: Wet chemical agents\\no The high heat release rate and propensity to retain \\nsufficient heat to reignite in fires with cooking oils pose a \\ngreater hazard than typical hydrocarbon fuels. \\no Wet chemical systems are used that contain \\no Potassium acetate or potassium citrate. \\no When discharged into the burning fuel, it reacts with the \\nvegetable oil to create soapy foam (saponification) that \\nexcludes oxygen from the fuel surface.\\no Simultaneously, the chemical cools the liquid surface \\nto below its ignition temperature.\\nExtinguishment of Fire'), 0.6032733), (Document(id='662f7fca-3450-4be2-9512-f10f8dfefb04', metadata={'total_pages': 31, 'file_type': '.pdf', 'semester': '1', 'teacher_info': 'Dr. Md. Ashiqur Rahman', 'page_number': 5, 'course': 'Refrigeration and Building Mechanical System', 'teacher': 'ashiqur', 'file_name': 'Lecture 3_ME 415_Extinguishment of Fire_26 April 2025', 'chunk_index': 0, 'content_type': 'lectures', 'course_code': 'ME415', 'document_type': 'lecture', 'academic_year': '4', 'source_path': 'data\\\\courses\\\\Refrigeration and Building Mechanical System\\\\lectures\\\\ashiqur\\\\Lecture 3_ME 415_Extinguishment of Fire_26 April 2025.pdf'}, page_content=\"ME 415 Md. Ashiqur Rahman\\nFire Tetrahedron\\no There are four fire extinguishing principles as per the fire \\ntetrahedron. \\na) Control the fuel: \\n− Controlling the fuel is accomplished by two methods. \\n− First, the fuel can be physically removed or separated from the \\nfire. \\n− Removing solid fuel in the path of the fire (firebreak in forest \\nfire). \\n− Removing cargo from a ship's hold\\n− Closing a valve feeding a gas or flammable liquid. \\n− Second, the fuel can be chemically affected by diluting the fuel. \\n− Reducing the flammability of polymer composites by dispersing \\nflame-retardant fillers and additives (antimony trioxide or \\naluminum hydroxide).\"), 0.6055968), (Document(id='08046eab-4999-4958-bd30-0cdbec895db2', metadata={'teacher_info': 'Dr. Md. Ashiqur Rahman', 'course': 'Refrigeration and Building Mechanical System', 'course_code': 'ME415', 'content_type': 'lectures', 'page_number': 5, 'chunk_index': 0, 'total_pages': 31, 'document_type': 'lecture', 'file_name': 'Lecture 2_ME 415_Basics on Fire Dynamics_19 April 2025', 'teacher': 'ashiqur', 'semester': '1', 'source_path': 'data\\\\courses\\\\Refrigeration and Building Mechanical System\\\\lectures\\\\ashiqur\\\\Lecture 2_ME 415_Basics on Fire Dynamics_19 April 2025.pdf', 'academic_year': '4', 'file_type': '.pdf'}, page_content='ME 415 Md. Ashiqur Rahman, ME, BUET\\nFire scenarios: \\n\\uf09b Open Fire: \\n\\uf09b Open fire means the burning of any matter in such a manner \\nthat the products of combustion resulting from such fires are \\nemitted directly into the ambient air without passing through \\nan adequate stack, duct, or chimney.\\n\\uf09b Wildfire\\nFire Fundamentals\\n\\uf09b A wildfire, bushfire, wildland fire, \\nor forest fire is an unplanned, \\nuncontrolled fire in an area \\nof combustible vegetation.'), 0.63882506)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 13:29:02,101 - httpx - INFO - HTTP Request: POST http://localhost:9999/api/v2/tenants/default_tenant/databases/default_database/collections/4b254101-5eb3-4574-93bf-13c7c83010d8/query \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(Document(id='bd856e97-7781-4300-a6c9-68e0fab684e1', metadata={'chunk_index': 1, 'file_name': 'Rao 6th ed', 'page_number': 161, 'content_type': 'books', 'course': 'Noise and Vibration', 'file_type': '.pdf', 'subject_area': 'general', 'document_type': 'textbook', 'total_pages': 1291, 'source_path': 'data\\\\courses\\\\Noise and Vibration\\\\books\\\\Rao 6th ed.pdf'}, page_content='F  \\n>\\n1t2 - mx  \\n>¶ = 0 (2.4a) \\n M  \\n>\\n1t2 - Ju  \\n>¶ = 0 (2.4b) \\nThese equations can be considered equilibrium equations provided that -mx >¶ and -Ju  \\n>¶ are \\ntreated as a force and a moment, respectively. This fictitious force (or moment) is known \\nas the inertia force (or inertia moment) and the artificial state of equilibrium implied by \\nEq. (2.4a) or (2.4b) is known as dynamic equilibrium. This principle, implied in Eq. (2.4a) \\nor (2.4b), is called D’Alembert’s principle. Applying it to the system shown in Fig. 2.1(c) \\nyields the equation of motion:\\n \\n-kx - mx$ = 0 or mx$ + kx = 0 (2.3) \\nPrinciple of Virtual Displacements. The principle of virtual displacements states that \\n“if a system that is in equilibrium under the action of a set of forces is subjected to a virtual \\ndisplacement, then the total virtual work done by the forces will be zero.” Here the virtual \\ndisplacement is defined as an imaginary infinitesimal displacement given instantaneously.'), 0.57854897), (Document(id='3035b743-59d4-415e-950b-8887ab0737c9', metadata={'source_path': 'data\\\\courses\\\\Noise and Vibration\\\\books\\\\Rao 6th ed.pdf', 'chunk_index': 1, 'subject_area': 'general', 'file_name': 'Rao 6th ed', 'document_type': 'textbook', 'total_pages': 1291, 'page_number': 610, 'course': 'Noise and Vibration', 'content_type': 'books', 'file_type': '.pdf'}, page_content='tion, the free-body diagrams of the masses can be developed as indicated in Fig. 6.6(e). The force \\nequilibrium equations of the masses are:\\n  Mass m1: k12 + k2 = 0  (E.5) \\n  Mass m2: k22 - k3 = k2 (E.6) \\n  Mass m3: k32 = - k3  (E.7) \\nThe solution of Eqs. (E.5)–(E.7) yields\\n \\nk12 = - k2,  k22 = k2 + k3,  k32 = - k3 (E.8) \\nFinally the set of forces ki3  1i = 1, 2, 32 is assumed to maintain the system with x1 = 0, x2 = 0, \\nand x3 = 1 (Fig. 6.6(f)). The free-body diagrams of the various masses in this configuration are \\nshown in Fig. 6.6(g) and the force equilibrium equations lead to\\n \\n Mass m1: k13 = 0  (E.9) \\n  Mass m2: k23 + k3 = 0 (E.10) \\n  Mass m3: k33 = k3  (E.11) \\nThe solution of Eqs. (E.9)–(E.11) yields\\n \\nk13 = 0,  k23 = - k3,  k33 = k3 (E.12) \\nThus the stiffness matrix of the system is given by\\n [k] = C\\n1k1 + k22 - k2 0\\n- k2 1k2 + k32 - k3\\n0  - k3 k3\\nS (E.13)'), 0.6064182), (Document(id='1822d149-8c75-4b6d-8fd7-45992af642d0', metadata={'source_path': 'data\\\\courses\\\\Noise and Vibration\\\\books\\\\Rao 6th ed.pdf', 'subject_area': 'general', 'file_type': '.pdf', 'total_pages': 1291, 'course': 'Noise and Vibration', 'content_type': 'books', 'chunk_index': 2, 'page_number': 516, 'file_name': 'Rao 6th ed', 'document_type': 'textbook'}, page_content='respective equilibrium positions. The external forces f11t2 and f21t2 act on the masses \\nm1 and m2, respectively. The free-body diagrams of the masses m1 and m2 are shown in \\nFig. 5.5(b). The application of Newton’s second law of motion to each of the masses \\ngives the equations of motion:\\n \\n m1x $\\n1 + 1c1 + c22x #\\n1 - c2 x #\\n2 + 1k1 + k22x1 - k2x2 = f1 (5.1) \\n  m2x $\\n2 - c2x #\\n1 + 1c2 + c32x #\\n2 - k2x1 + 1k2 + k32x2 = f2 (5.2) \\nIt can be seen that Eq. (5.1) contains terms involving x2 (namely, -c2x #\\n2 and -k2x2), \\nwhereas Eq. (5.2) contains terms involving x1 (namely, -c2x#\\n1 and -k2x1). Hence they'), 0.63104606), (Document(id='867e4dbb-bba0-44da-a402-cc5dbad63069', metadata={'subject_area': 'general', 'chapter_number': 1, 'source_path': 'data\\\\courses\\\\Noise and Vibration\\\\books\\\\Rao 6th ed.pdf', 'file_name': 'Rao 6th ed', 'chapter_title': 'Fundamentals oF\\xa0Vibration', 'document_type': 'textbook', 'course': 'Noise and Vibration', 'content_type': 'books', 'page_number': 124, 'file_type': '.pdf', 'chunk_index': 0, 'total_pages': 1291}, page_content='122 Chapter 1  Fundamentals oF\\xa0Vibration\\n 1.18  The static equilibrium position of a massless rigid bar, hinged at point O and connected with \\nsprings k1 and k2, is shown in Fig. 1.74. Assuming that the displacement (x) resulting from \\nthe application of a force F at point A is small, find the equivalent spring constant of the sys-\\ntem, \\nke, that relates the applied force F to the displacement x as F = kex. \\nFiGure 1.73 A tripod carrying an electronic instrument.\\nFO\\nk2 /H11005 k\\nk1 /H11005 2k\\nx\\nA\\nl\\n4\\nl\\n4\\nl\\n2\\nl\\n4\\nFiGure 1.74 Rigid bar connected by springs.\\n 1.19  Figure 1.75 shows a system in which the mass m is directly connected to the springs with \\nstiffnesses \\nk1 and k2 while the spring with stiffness k3 or k4 comes into contact with the mass \\nbased on the value of the displacement of the mass. Determine the variation of the spring \\nforce exerted on the mass as the displacement of the mass (x) varies.'), 0.6350483), (Document(id='a67cc1d8-6487-433e-bda6-4ed29e042958', metadata={'file_type': '.pdf', 'file_name': 'Rao 6th ed', 'subject_area': 'general', 'document_type': 'textbook', 'source_path': 'data\\\\courses\\\\Noise and Vibration\\\\books\\\\Rao 6th ed.pdf', 'course': 'Noise and Vibration', 'page_number': 608, 'content_type': 'books', 'chunk_index': 2, 'total_pages': 1291}, page_content='equilibrium equations are written for each mass and the resulting set of n equations \\nsolved to find the n influence coefficients \\nkij 1i = 1, 2, c , n2. \\n2. After completing step 1 for j = 1, the procedure is repeated for j = 2, 3, c, n. \\nThe following examples illustrate the procedure.\\nexaMple 6.3 \\nStiffness influence Coefficients\\nFind the stiffness influence coefficients of the system shown in Fig. 6.6(a).\\nSolution: \\nApproach: Use the definition of kij and static equilibrium equations.\\nLet x1, x2, and x3 denote the displacements of the masses m1, m2, and m3, respectively. The \\nstiffness influence coefficients kij of the system can be determined in terms of the spring stiffnesses'), 0.64865375)]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def query_with_filters(query_text: str, db: Chroma, course=None, teacher=None, content_type=None, subject_area=None):\n",
    "    # Build filter based on parameters\n",
    "    filter_dict = {}\n",
    "    if course:\n",
    "        filter_dict[\"course\"] = course\n",
    "    if teacher:\n",
    "        filter_dict[\"teacher\"] = teacher\n",
    "    if content_type:\n",
    "        filter_dict[\"content_type\"] = content_type\n",
    "    if subject_area:\n",
    "        filter_dict[\"subject_area\"] = subject_area\n",
    "    \n",
    "    # Search with filters\n",
    "    results = db.similarity_search_with_score(\n",
    "        query_text, \n",
    "        k=5, \n",
    "        filter=filter_dict if filter_dict else None\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage:\n",
    "# Get only lecture content from Prof Smith\n",
    "results = query_with_filters(\n",
    "    \"fire\", \n",
    "    db=vector_db,\n",
    "    # course=\"mechanical_engineering\",\n",
    "    # teacher=\"prof_smith\",\n",
    "    content_type=\"lectures\"\n",
    ")\n",
    "print(results)\n",
    "# Get only book content about thermodynamics\n",
    "results = query_with_filters(\n",
    "    \"explain force equilibrium\",\n",
    "    db=vector_db,\n",
    "    # subject_area=\"thermodynamics\",\n",
    "    content_type=\"books\"\n",
    ")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
